{"cells":[{"cell_type":"markdown","source":["**Q3)**"],"metadata":{"id":"d7MtIjOWM2HG"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"8ZFe7K_ZttHD"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","from transformers import GPT2LMHeadModel, GPT2Tokenizer\n","from sklearn.model_selection import train_test_split\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4-ORvzYovOnd","outputId":"3504cea1-f723-400b-d444-dba90ce8ba1b","executionInfo":{"status":"ok","timestamp":1705685743336,"user_tz":-210,"elapsed":21029,"user":{"displayName":"Mohammadreza Bagheri","userId":"03166803211561808722"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KEQluK5kt3IK"},"outputs":[],"source":["dataset_path = \"/content/drive/MyDrive/DeepHW4/Q3/ferdousi.txt\"\n","with open(dataset_path, 'r', encoding='utf-8') as f:\n","    dataset = f.readlines()\n","\n","\n","input_poems = []\n","output_poems = []\n","for i in range(len(dataset) - 3):\n","    if i % 2 == 0:\n","        input_poems.append(dataset[i].strip() +  \" \" + dataset[i+1] .strip())    # processing the input line pairs\n","        # Tokenize the output line pairs\n","        output_poems.append(dataset[i+2].strip() +  \" \" + dataset[i+3] .strip()) # processing the desired output line pairs\n","\n","\n","print(input_poems[0])  # Example input\n","print(output_poems[0])  # Example output\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9wX9wFpjv03K"},"outputs":[],"source":["class shahNamehDataset(Dataset):\n","    def __init__(self, input_poem,output_poem, tokenizer):\n","        self.input_poem = input_poem\n","        self.output_poem = output_poem\n","        self.tokenizer = tokenizer\n","\n","    def __len__(self):\n","        return len(self.input_poem)\n","\n","    def __getitem__(self, idx):\n","        poem_in = self.input_poem[idx].strip()\n","        poem_out = self.output_poem[idx].strip()\n","        return poem_in, poem_out\n","\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(\"HooshvareLab/gpt2-fa\")  # Load the pre-trained tokenizer\n","\n","\n","train_dataset = shahNamehDataset(input_poems,output_poems, tokenizer)\n","train_dataset, test_dataset = train_test_split(train_dataset, test_size=0.2, random_state=42)\n","\n","\n","batch_size = 64\n","\n","\n","train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_data_loader =  DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8OidhqV9v_fH"},"outputs":[],"source":["# Loading the pre-trained model\n","model = GPT2LMHeadModel.from_pretrained(\"HooshvareLab/gpt2-fa\")\n","\n","# Setting the training loop\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)\n","model.train()\n","\n","\n","# Setting the optimizer and loss function\n","optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n","loss_fn = torch.nn.CrossEntropyLoss()\n","tokenizer.pad_token = tokenizer.eos_token\n"]},{"cell_type":"code","source":["max_length = 15\n","epochs = 100\n","for epoch in range(epochs):\n","    model.train()\n","    train_loss = 0\n","    print('epoch',epoch)\n","    for batch_in, batch_out in train_data_loader:\n","        # Tokenizing input and output sequences\n","        inputs = tokenizer(batch_in, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length).to(device)\n","        labels = tokenizer(batch_out, padding=True, truncation=True, return_tensors=\"pt\", max_length=max_length).input_ids.to(device)\n","\n","\n","        # Forward pass\n","        outputs = model(**inputs, labels=labels)\n","        loss = outputs.loss\n","\n","        # Backward pass and optimization\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","\n","    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {train_loss / len(train_data_loader):.4f}\")\n"],"metadata":{"id":"b2yaLgvswyL5"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4xBedUESwhTj","outputId":"6e766f4b-b086-43d3-8189-d3ed893d227c","executionInfo":{"status":"ok","timestamp":1705694995641,"user_tz":-210,"elapsed":790,"user":{"displayName":"Mohammadreza Bagheri","userId":"03166803211561808722"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:5 for open-end generation.\n"]},{"output_type":"stream","name":"stdout","text":["ریاضی را تو الحق خوب دانی و خوب دانی تو خوب\n"]},{"output_type":"execute_result","data":{"text/plain":["Ellipsis"]},"metadata":{},"execution_count":45}],"source":["model.eval() #Setting the model to evaluation mode\n","\n","tokenizer.pad_token_id = tokenizer.eos_token_id\n","input_text = \"ریاضی را تو الحق خوب دانی\"  # Generate poem using the trained model\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").to(device)\n","outputs = model.generate(**input_ids, max_length=11)\n","\n","generated_poems = []\n","for output in outputs:\n","    poem = tokenizer.decode(output, skip_special_tokens=True )\n","    generated_poems.append(poem)\n","    print(poem)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}